{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.模型的保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suncheng/anaconda3/envs/wenet/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一会将此模型进行本地保存\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存方式一：保存模型结构+参数\n",
    "torch.save(vgg16, 'vgg16_method_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载保存的模型\n",
    "model = torch.load('vgg16_method_1.pth')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存方式二：保存模型参数[官方推荐的方式] 这种保存方式比方式一要小\n",
    "torch.save(vgg16.state_dict(), 'vgg16_method_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载方式二保存的模型\n",
    "# torch.load('vgg16_method_2.pth')    # 得到的是参数字典\n",
    "\n",
    "# 要想重建模型，需要再定义模型然后加载此权重\n",
    "model_method_2 = torchvision.models.vgg16()\n",
    "model_method_2.load_state_dict(torch.load('vgg16_method_2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用方式一保存的陷阱\n",
    "# 比如现在有一个自定义模型\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3, 32, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# 实例化自定义模型\n",
    "mymodel = MyModel()\n",
    "# 方式一保存自定义模型\n",
    "torch.save(mymodel, 'mymodel_method_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'MyModel' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 自定义模型方式一加载时会出现问题\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# 我这里没出问题，因为上面定义了MyModel模型结构，如果没定义的话会报错\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mmymodel_method_1.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/serialization.py:607\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m             opened_file\u001b[39m.\u001b[39mseek(orig_position)\n\u001b[1;32m    606\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 607\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/serialization.py:882\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m    881\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m--> 882\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    884\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m    886\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/wenet/lib/python3.8/site-packages/torch/serialization.py:875\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_class\u001b[39m(\u001b[39mself\u001b[39m, mod_name, name):\n\u001b[1;32m    874\u001b[0m     mod_name \u001b[39m=\u001b[39m load_module_mapping\u001b[39m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m--> 875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfind_class(mod_name, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'MyModel' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# 自定义模型方式一加载时会出现问题\n",
    "# 我这里没出问题，因为上面定义了MyModel模型结构，如果没定义的话会报错。报错也复现了\n",
    "torch.load('mymodel_method_1.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.完整的训练套路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "train_dataset长度为:50000\n",
      "test_dataset长度为:10000\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集\n",
    "train_dataset = torchvision.datasets.CIFAR10('data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10('data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "print(f'train_dataset长度为:{len(train_dataset)}\\ntest_dataset长度为:{len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_train_step:100  loss:2.2911484\n",
      "total_train_step:200  loss:2.3007643\n",
      "total_train_step:300  loss:2.2574663\n",
      "total_train_step:400  loss:2.2474570\n",
      "total_train_step:500  loss:2.1314514\n",
      "total_train_step:600  loss:2.0383046\n",
      "total_train_step:700  loss:1.9208713\n",
      "--------------------> test acc:0.29659998416900635 test loss total:308.2482300\n",
      "total_train_step:800  loss:1.9407473\n",
      "total_train_step:900  loss:1.9111099\n",
      "total_train_step:1000  loss:1.9652811\n",
      "total_train_step:1100  loss:1.7590046\n",
      "total_train_step:1200  loss:1.8395827\n",
      "total_train_step:1300  loss:1.7512043\n",
      "total_train_step:1400  loss:1.8687602\n",
      "total_train_step:1500  loss:1.8587788\n",
      "--------------------> test acc:0.2586999833583832 test loss total:337.0223083\n",
      "total_train_step:1600  loss:1.6178354\n",
      "total_train_step:1700  loss:1.7533450\n",
      "total_train_step:1800  loss:1.7263081\n",
      "total_train_step:1900  loss:1.6362153\n",
      "total_train_step:2000  loss:1.4000463\n",
      "total_train_step:2100  loss:1.7219518\n",
      "total_train_step:2200  loss:1.4748170\n",
      "total_train_step:2300  loss:1.7318239\n",
      "--------------------> test acc:0.43309998512268066 test loss total:249.2621460\n",
      "total_train_step:2400  loss:1.6814929\n",
      "total_train_step:2500  loss:1.6380720\n",
      "total_train_step:2600  loss:1.4291743\n",
      "total_train_step:2700  loss:1.6491086\n",
      "total_train_step:2800  loss:1.3820502\n",
      "total_train_step:2900  loss:1.4458448\n",
      "total_train_step:3000  loss:1.5281588\n",
      "total_train_step:3100  loss:1.7308550\n",
      "--------------------> test acc:0.46289998292922974 test loss total:233.5715942\n",
      "total_train_step:3200  loss:1.4239773\n",
      "total_train_step:3300  loss:1.3194025\n",
      "total_train_step:3400  loss:1.4679507\n",
      "total_train_step:3500  loss:1.5022875\n",
      "total_train_step:3600  loss:1.4254010\n",
      "total_train_step:3700  loss:1.5454159\n",
      "total_train_step:3800  loss:1.5056117\n",
      "total_train_step:3900  loss:1.5433354\n",
      "--------------------> test acc:0.4691999852657318 test loss total:231.8496246\n",
      "total_train_step:4000  loss:1.3586748\n",
      "total_train_step:4100  loss:1.2777078\n",
      "total_train_step:4200  loss:1.6598341\n",
      "total_train_step:4300  loss:1.4741261\n",
      "total_train_step:4400  loss:1.4184699\n",
      "total_train_step:4500  loss:1.3017462\n",
      "total_train_step:4600  loss:1.3646588\n",
      "--------------------> test acc:0.4527999758720398 test loss total:239.5017700\n",
      "total_train_step:4700  loss:1.3681874\n",
      "total_train_step:4800  loss:1.1773126\n",
      "total_train_step:4900  loss:1.1687871\n",
      "total_train_step:5000  loss:1.3693635\n",
      "total_train_step:5100  loss:1.5412033\n",
      "total_train_step:5200  loss:1.3777384\n",
      "total_train_step:5300  loss:1.4248383\n",
      "total_train_step:5400  loss:1.4903214\n",
      "--------------------> test acc:0.5309999585151672 test loss total:204.6221466\n",
      "total_train_step:5500  loss:1.2804052\n",
      "total_train_step:5600  loss:1.4587348\n",
      "total_train_step:5700  loss:1.2285227\n",
      "total_train_step:5800  loss:1.2594980\n",
      "total_train_step:5900  loss:1.1945159\n",
      "total_train_step:6000  loss:1.2128540\n",
      "total_train_step:6100  loss:1.1126523\n",
      "total_train_step:6200  loss:1.1642864\n",
      "--------------------> test acc:0.5598999857902527 test loss total:194.0925446\n",
      "total_train_step:6300  loss:1.2613471\n",
      "total_train_step:6400  loss:1.0383139\n",
      "total_train_step:6500  loss:1.2482189\n",
      "total_train_step:6600  loss:1.1682911\n",
      "total_train_step:6700  loss:1.1647954\n",
      "total_train_step:6800  loss:1.2876441\n",
      "total_train_step:6900  loss:1.2405964\n",
      "total_train_step:7000  loss:1.2910272\n",
      "--------------------> test acc:0.5072000026702881 test loss total:215.2030334\n",
      "total_train_step:7100  loss:0.9941420\n",
      "total_train_step:7200  loss:0.9406542\n",
      "total_train_step:7300  loss:1.2623369\n",
      "total_train_step:7400  loss:1.1633291\n",
      "total_train_step:7500  loss:1.1322567\n",
      "total_train_step:7600  loss:1.0493590\n",
      "total_train_step:7700  loss:1.2848800\n",
      "total_train_step:7800  loss:1.1201946\n",
      "--------------------> test acc:0.5631999969482422 test loss total:195.3418427\n",
      "total_train_step:7900  loss:1.1055386\n",
      "total_train_step:8000  loss:1.0284697\n",
      "total_train_step:8100  loss:1.0587906\n",
      "total_train_step:8200  loss:0.9965760\n",
      "total_train_step:8300  loss:1.1731749\n",
      "total_train_step:8400  loss:0.9350346\n",
      "total_train_step:8500  loss:1.1922812\n",
      "total_train_step:8600  loss:0.9049227\n",
      "--------------------> test acc:0.5216999650001526 test loss total:226.9306641\n",
      "total_train_step:8700  loss:0.9187900\n",
      "total_train_step:8800  loss:0.9305815\n",
      "total_train_step:8900  loss:1.1850723\n",
      "total_train_step:9000  loss:1.3141353\n",
      "total_train_step:9100  loss:1.1338086\n",
      "total_train_step:9200  loss:1.1576617\n",
      "total_train_step:9300  loss:1.2042649\n",
      "--------------------> test acc:0.593999981880188 test loss total:182.7668915\n",
      "total_train_step:9400  loss:0.8576135\n",
      "total_train_step:9500  loss:0.9612536\n",
      "total_train_step:9600  loss:0.6730579\n",
      "total_train_step:9700  loss:0.8353029\n",
      "total_train_step:9800  loss:1.1302630\n",
      "total_train_step:9900  loss:0.9441794\n",
      "total_train_step:10000  loss:1.0679157\n",
      "total_train_step:10100  loss:0.9989725\n",
      "--------------------> test acc:0.604200005531311 test loss total:180.1737366\n",
      "total_train_step:10200  loss:0.9605246\n",
      "total_train_step:10300  loss:1.1050107\n",
      "total_train_step:10400  loss:0.7415974\n",
      "total_train_step:10500  loss:0.9756795\n",
      "total_train_step:10600  loss:0.9399277\n",
      "total_train_step:10700  loss:1.0318321\n",
      "total_train_step:10800  loss:0.9275568\n",
      "total_train_step:10900  loss:0.8496140\n",
      "--------------------> test acc:0.6146000027656555 test loss total:174.8921356\n",
      "total_train_step:11000  loss:1.0100414\n",
      "total_train_step:11100  loss:0.9983582\n",
      "total_train_step:11200  loss:0.9933015\n",
      "total_train_step:11300  loss:0.8954619\n",
      "total_train_step:11400  loss:1.0223060\n",
      "total_train_step:11500  loss:0.9912210\n",
      "total_train_step:11600  loss:1.0819956\n",
      "total_train_step:11700  loss:1.2030346\n",
      "--------------------> test acc:0.630899965763092 test loss total:168.3582916\n",
      "total_train_step:11800  loss:1.0903302\n",
      "total_train_step:11900  loss:0.7213988\n",
      "total_train_step:12000  loss:0.8942876\n",
      "total_train_step:12100  loss:0.9485323\n",
      "total_train_step:12200  loss:0.9270916\n",
      "total_train_step:12300  loss:1.2527990\n",
      "total_train_step:12400  loss:1.0055088\n",
      "total_train_step:12500  loss:0.8896849\n",
      "--------------------> test acc:0.6385999917984009 test loss total:166.6390076\n",
      "total_train_step:12600  loss:0.9206019\n",
      "total_train_step:12700  loss:1.0654954\n",
      "total_train_step:12800  loss:0.9191309\n",
      "total_train_step:12900  loss:0.6981200\n",
      "total_train_step:13000  loss:0.9154525\n",
      "total_train_step:13100  loss:0.9139681\n",
      "total_train_step:13200  loss:0.9273498\n",
      "--------------------> test acc:0.6403999924659729 test loss total:165.5500793\n",
      "total_train_step:13300  loss:1.0254836\n",
      "total_train_step:13400  loss:0.8539247\n",
      "total_train_step:13500  loss:0.8867825\n",
      "total_train_step:13600  loss:1.0115234\n",
      "total_train_step:13700  loss:1.0437369\n",
      "total_train_step:13800  loss:1.2006888\n",
      "total_train_step:13900  loss:0.6198980\n",
      "total_train_step:14000  loss:0.7071260\n",
      "--------------------> test acc:0.6306999921798706 test loss total:172.4969788\n",
      "total_train_step:14100  loss:0.8905495\n",
      "total_train_step:14200  loss:0.8536591\n",
      "total_train_step:14300  loss:0.9932165\n",
      "total_train_step:14400  loss:0.8580198\n",
      "total_train_step:14500  loss:0.8420135\n",
      "total_train_step:14600  loss:0.8632543\n",
      "total_train_step:14700  loss:0.8603466\n",
      "total_train_step:14800  loss:0.8703796\n",
      "--------------------> test acc:0.6121999621391296 test loss total:181.5316772\n",
      "total_train_step:14900  loss:1.0317974\n",
      "total_train_step:15000  loss:0.8759987\n",
      "total_train_step:15100  loss:0.8362036\n",
      "total_train_step:15200  loss:1.0641716\n",
      "total_train_step:15300  loss:0.9277135\n",
      "total_train_step:15400  loss:0.6829305\n",
      "total_train_step:15500  loss:0.9300970\n",
      "total_train_step:15600  loss:0.8321662\n",
      "--------------------> test acc:0.6378999948501587 test loss total:167.6421509\n",
      "total_train_step:15700  loss:0.7810697\n",
      "total_train_step:15800  loss:0.6483533\n",
      "total_train_step:15900  loss:0.7927418\n",
      "total_train_step:16000  loss:0.7168665\n",
      "total_train_step:16100  loss:0.7864918\n",
      "total_train_step:16200  loss:0.6986147\n",
      "total_train_step:16300  loss:0.7127424\n",
      "total_train_step:16400  loss:0.7977275\n",
      "--------------------> test acc:0.6082000136375427 test loss total:186.5911865\n",
      "total_train_step:16500  loss:0.9159350\n",
      "total_train_step:16600  loss:0.7434846\n",
      "total_train_step:16700  loss:0.8133772\n",
      "total_train_step:16800  loss:0.6231858\n",
      "total_train_step:16900  loss:0.9093140\n",
      "total_train_step:17000  loss:0.7771766\n",
      "total_train_step:17100  loss:0.7977844\n",
      "total_train_step:17200  loss:0.5887169\n",
      "--------------------> test acc:0.6123999953269958 test loss total:180.7318115\n",
      "total_train_step:17300  loss:0.7349932\n",
      "total_train_step:17400  loss:0.6529127\n",
      "total_train_step:17500  loss:0.7491109\n",
      "total_train_step:17600  loss:0.7008013\n",
      "total_train_step:17700  loss:0.7533014\n",
      "total_train_step:17800  loss:0.7487006\n",
      "total_train_step:17900  loss:0.6547975\n",
      "--------------------> test acc:0.6417999863624573 test loss total:170.8517456\n",
      "total_train_step:18000  loss:0.5848483\n",
      "total_train_step:18100  loss:0.8042054\n",
      "total_train_step:18200  loss:0.6086643\n",
      "total_train_step:18300  loss:0.8421055\n",
      "total_train_step:18400  loss:0.7966636\n",
      "total_train_step:18500  loss:0.7663627\n",
      "total_train_step:18600  loss:0.7372247\n",
      "total_train_step:18700  loss:0.9161188\n",
      "--------------------> test acc:0.611299991607666 test loss total:188.6173706\n",
      "total_train_step:18800  loss:0.9220044\n",
      "total_train_step:18900  loss:0.6282091\n",
      "total_train_step:19000  loss:0.9056728\n",
      "total_train_step:19100  loss:0.5663710\n",
      "total_train_step:19200  loss:0.8289514\n",
      "total_train_step:19300  loss:0.6615446\n",
      "total_train_step:19400  loss:0.4678061\n",
      "total_train_step:19500  loss:0.4676949\n",
      "--------------------> test acc:0.6665999889373779 test loss total:157.1840515\n",
      "total_train_step:19600  loss:0.4334560\n",
      "total_train_step:19700  loss:0.7384936\n",
      "total_train_step:19800  loss:0.4244432\n",
      "total_train_step:19900  loss:0.6761073\n",
      "total_train_step:20000  loss:0.5863087\n",
      "total_train_step:20100  loss:0.5072505\n",
      "total_train_step:20200  loss:0.7171296\n",
      "total_train_step:20300  loss:1.0523165\n",
      "--------------------> test acc:0.6739999651908875 test loss total:155.6654358\n",
      "total_train_step:20400  loss:0.5436895\n",
      "total_train_step:20500  loss:0.7343562\n",
      "total_train_step:20600  loss:0.6998774\n",
      "total_train_step:20700  loss:0.7733405\n",
      "total_train_step:20800  loss:0.7917731\n",
      "total_train_step:20900  loss:0.8410684\n",
      "total_train_step:21000  loss:0.6826570\n",
      "total_train_step:21100  loss:0.7407214\n",
      "--------------------> test acc:0.5928999781608582 test loss total:212.4049377\n",
      "total_train_step:21200  loss:0.6602033\n",
      "total_train_step:21300  loss:0.7738401\n",
      "total_train_step:21400  loss:0.7776948\n",
      "total_train_step:21500  loss:0.8790916\n",
      "total_train_step:21600  loss:0.7360075\n",
      "total_train_step:21700  loss:0.7419851\n",
      "total_train_step:21800  loss:0.7196602\n",
      "--------------------> test acc:0.6638000011444092 test loss total:157.4412842\n",
      "total_train_step:21900  loss:0.5154006\n",
      "total_train_step:22000  loss:0.5202134\n",
      "total_train_step:22100  loss:0.7672830\n",
      "total_train_step:22200  loss:0.5576678\n",
      "total_train_step:22300  loss:0.6860927\n",
      "total_train_step:22400  loss:0.5685796\n",
      "total_train_step:22500  loss:0.7507272\n",
      "total_train_step:22600  loss:0.4879481\n",
      "--------------------> test acc:0.6367999911308289 test loss total:176.1847687\n",
      "total_train_step:22700  loss:0.5732341\n",
      "total_train_step:22800  loss:0.8068624\n",
      "total_train_step:22900  loss:0.6507110\n",
      "total_train_step:23000  loss:0.6162318\n",
      "total_train_step:23100  loss:0.4913775\n",
      "total_train_step:23200  loss:0.6725320\n",
      "total_train_step:23300  loss:0.9137176\n",
      "total_train_step:23400  loss:0.5377009\n",
      "--------------------> test acc:0.6295999884605408 test loss total:184.1269836\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "loss可以上cuda，model可以上cuda，数据可以在迭代时上cuda\n",
    "\"\"\"\n",
    "# 实例化自定义模型，复制过来\n",
    "from model import MySequence\n",
    "\n",
    "model = MySequence()\n",
    "model = model.cuda()    # model上GPU\n",
    "\n",
    "# 定义loss和optim\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss = loss.cuda()  # loss上GPU\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# 定义一些参数\n",
    "total_train_step = 0    # 记录训练的次数\n",
    "total_test_step = 0     # 记录测试的次数\n",
    "epochs = 30\n",
    "\n",
    "# 训练过程loss可视化\n",
    "writer = SummaryWriter('logs')\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        imgs, labels = data\n",
    "        imgs, labels = imgs.cuda(), labels.cuda()\n",
    "        outs = model(imgs)\n",
    "        l = loss(outs, labels)\n",
    "        writer.add_scalar('train loss', l.item(), total_train_step)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step += 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(f'total_train_step:{total_train_step}  loss:{l:.7f}')\n",
    "    \n",
    "    # 测试步骤，因为不需要优化，所以取消梯度计算\n",
    "    with torch.no_grad():\n",
    "        loss_test = 0\n",
    "        test_acc = 0\n",
    "        for data in test_loader:\n",
    "            imgs, labels = data\n",
    "            imgs, labels = imgs.cuda(), labels.cuda()\n",
    "            outs = model(imgs)\n",
    "            test_acc += (outs.argmax(dim=1) == labels).sum()\n",
    "            loss_test += loss(outs, labels)\n",
    "        writer.add_scalar('test loss', loss_test.item(), total_test_step)\n",
    "        writer.add_scalar('test accuracy', test_acc / len(test_loader.dataset), total_test_step)\n",
    "        total_test_step += 1\n",
    "        print(f'--------------------> test acc:{test_acc / len(test_loader.dataset)} test loss total:{loss_test:.7f}')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.模型推断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgTensor torch.Size([1, 3, 32, 32])\n",
      "output torch.Size([1, 10]) class: tensor([0], device='cuda:0')\n",
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    image = Image.open('data/images/2007_000033.jpg')\n",
    "    imgTensor = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                    transforms.ToTensor()])(image).unsqueeze(0).cuda()\n",
    "    print(f'imgTensor {imgTensor.shape}')\n",
    "    output = model(imgTensor)\n",
    "    print(f'output {output.shape} class: {output.argmax(-1)}\\n{test_dataset.class_to_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
