{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def cls_predictor(num_inputs, num_anchors, num_classes):\n",
    "    return nn.Conv2d(num_inputs, num_anchors * (num_classes + 1), kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_predictor(num_inputs, num_anchors):\n",
    "    return nn.Conv2d(num_inputs, num_anchors * 4, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 55, 20, 20]), torch.Size([2, 33, 10, 10]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(x, block):\n",
    "    return block(x)\n",
    "\n",
    "Y1 = forward(torch.zeros(size=(2, 8, 20, 20)), cls_predictor(8, 5, 10))\n",
    "Y2 = forward(torch.zeros(size=(2, 16, 10, 10)), cls_predictor(16, 3, 10))\n",
    "Y1.shape, Y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_pred(pred):\n",
    "    return torch.flatten(pred.permute(0, 2, 3, 1), start_dim=1)     # 从start_dim维度开始展平\n",
    "\n",
    "def concat_preds(preds):\n",
    "    return torch.cat([flatten_pred(p) for p in preds], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 25300])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_preds([Y1, Y2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample_blk(in_channels, out_channels):\n",
    "    blk = []\n",
    "    for _ in range(2):\n",
    "        blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.BatchNorm2d(out_channels))\n",
    "        in_channels = out_channels\n",
    "    blk.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 10, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(torch.zeros((2, 3, 20, 20)), down_sample_blk(3, 10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def base_net():\n",
    "    \"\"\" 基本网络块 \"\"\"\n",
    "    blk = []\n",
    "    num_filters = [3, 16, 32, 64]\n",
    "    for i in range(len(num_filters) - 1):\n",
    "        blk.append(down_sample_blk(num_filters[i], num_filters[i + 1]))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "forward(torch.zeros((2, 3, 256, 256)), base_net()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blk(i):\n",
    "    if i == 0:\n",
    "        blk = base_net()\n",
    "    elif i == 1:\n",
    "        blk = down_sample_blk(64, 128)\n",
    "    elif i == 4:\n",
    "        blk = nn.AdaptiveMaxPool2d(output_size=(1, 1))\n",
    "    else:\n",
    "        blk = down_sample_blk(128, 128)\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):\n",
    "    \"\"\" 每个块的前向传播，输出包括：特征图、锚框、预测类别和偏移量 \"\"\"\n",
    "    Y = blk(X)\n",
    "    anchors = d2l.multibox_prior(Y, size, ratio)\n",
    "    cls_preds = cls_predictor(Y)\n",
    "    bbox_preds = bbox_predictor(Y)\n",
    "    return (Y, anchors, cls_preds, bbox_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],\n",
    "         [0.88, 0.961]]\n",
    "ratios = [[1, 2, 0.5]] * 5\n",
    "num_anchors = len(sizes[0]) + len(ratios[0]) - 1    # 应该是每个像素有n + m - 1个anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinySSD(nn.Module):\n",
    "    def __init__(self, num_classes, **kwargs) -> None:\n",
    "        super(TinySSD, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        idx_to_in_channels = [64, 128, 128, 128, 128]\n",
    "        for i in range(5):\n",
    "            setattr(self, f'blk_{i}', get_blk(i))\n",
    "            setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i], num_anchors, num_classes))\n",
    "            setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i], num_anchors))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5\n",
    "        for i in range(5):\n",
    "            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(X, \n",
    "                                                            getattr(self, f'blk_{i}'), \n",
    "                                                            sizes[i], \n",
    "                                                            ratios[i], \n",
    "                                                            getattr(self, f'cls_{i}'), \n",
    "                                                            getattr(self, f'bbox_{i}'))\n",
    "        anchors = torch.cat(anchors, dim=1)\n",
    "        cls_preds = concat_preds(cls_preds)\n",
    "        cls_preds = cls_preds.reshape(cls_preds.shape[0], -1, self.num_classes + 1)\n",
    "        bbox_preds = concat_preds(bbox_preds)\n",
    "        return anchors, cls_preds, bbox_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output anchors:torch.Size([1, 5444, 4])\n",
      "output class preds:torch.Size([32, 5444, 2])\n",
      "output bbox preds:torch.Size([32, 21776])\n"
     ]
    }
   ],
   "source": [
    "net = TinySSD(num_classes=1)\n",
    "X = torch.zeros(size=(32, 3, 256, 256))\n",
    "anchors, cls_preds, bbox_preds = net(X)\n",
    "\n",
    "print(f'output anchors:{anchors.shape}')\n",
    "print(f'output class preds:{cls_preds.shape}')\n",
    "print(f'output bbox preds:{bbox_preds.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No such operator image::read_file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\D2L\\第13章\\13.5单发多框检测SSD.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.5%E5%8D%95%E5%8F%91%E5%A4%9A%E6%A1%86%E6%A3%80%E6%B5%8BSSD.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.5%E5%8D%95%E5%8F%91%E5%A4%9A%E6%A1%86%E6%A3%80%E6%B5%8BSSD.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_iter, _ \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39;49mload_data_bananas(batch_size)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\d2l\\torch.py:1883\u001b[0m, in \u001b[0;36mload_data_bananas\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m   1879\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data_bananas\u001b[39m(batch_size):\n\u001b[0;32m   1880\u001b[0m     \u001b[39m\"\"\"Load the banana detection dataset.\u001b[39;00m\n\u001b[0;32m   1881\u001b[0m \n\u001b[0;32m   1882\u001b[0m \u001b[39m    Defined in :numref:`sec_object-detection-dataset`\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1883\u001b[0m     train_iter \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(BananasDataset(is_train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m   1884\u001b[0m                                              batch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1885\u001b[0m     val_iter \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(BananasDataset(is_train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m                                            batch_size)\n\u001b[0;32m   1887\u001b[0m     \u001b[39mreturn\u001b[39;00m train_iter, val_iter\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\d2l\\torch.py:1869\u001b[0m, in \u001b[0;36mBananasDataset.__init__\u001b[1;34m(self, is_train)\u001b[0m\n\u001b[0;32m   1868\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, is_train):\n\u001b[1;32m-> 1869\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m read_data_bananas(is_train)\n\u001b[0;32m   1870\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mread \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)) \u001b[39m+\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m training examples\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m\n\u001b[0;32m   1871\u001b[0m           is_train \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m validation examples\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\d2l\\torch.py:1855\u001b[0m, in \u001b[0;36mread_data_bananas\u001b[1;34m(is_train)\u001b[0m\n\u001b[0;32m   1853\u001b[0m images, targets \u001b[39m=\u001b[39m [], []\n\u001b[0;32m   1854\u001b[0m \u001b[39mfor\u001b[39;00m img_name, target \u001b[39min\u001b[39;00m csv_data\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m-> 1855\u001b[0m     images\u001b[39m.\u001b[39mappend(torchvision\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mread_image(\n\u001b[0;32m   1856\u001b[0m         os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(data_dir, \u001b[39m'\u001b[39;49m\u001b[39mbananas_train\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mif\u001b[39;49;00m is_train \u001b[39melse\u001b[39;49;00m\n\u001b[0;32m   1857\u001b[0m                      \u001b[39m'\u001b[39;49m\u001b[39mbananas_val\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mimages\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mimg_name\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)))\n\u001b[0;32m   1858\u001b[0m     \u001b[39m# Here `target` contains (class, upper-left x, upper-left y,\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m     \u001b[39m# lower-right x, lower-right y), where all the images have the same\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m     \u001b[39m# banana class (index 0)\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m     targets\u001b[39m.\u001b[39mappend(\u001b[39mlist\u001b[39m(target))\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torchvision\\io\\image.py:222\u001b[0m, in \u001b[0;36mread_image\u001b[1;34m(path, mode)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_image\u001b[39m(path: \u001b[39mstr\u001b[39m, mode: ImageReadMode \u001b[39m=\u001b[39m ImageReadMode\u001b[39m.\u001b[39mUNCHANGED) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    Reads a JPEG or PNG image into a 3 dimensional RGB Tensor.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39m    Optionally converts the image to the desired format.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39m        output (Tensor[image_channels, image_height, image_width])\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     data \u001b[39m=\u001b[39m read_file(path)\n\u001b[0;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m decode_image(data, mode)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torchvision\\io\\image.py:42\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_file\u001b[39m(path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m     32\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m    Reads and outputs the bytes contents of a file as a uint8 Tensor\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m    with one dimension.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m        data (Tensor)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mread_file(path)\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torch\\_ops.py:63\u001b[0m, in \u001b[0;36m_OpNamespace.__getattr__\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m# Get the op `my_namespace::my_op` if available. This will also check\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m# for overloads and raise an exception if there are more than one.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m qualified_op_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m::\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, op_name)\n\u001b[1;32m---> 63\u001b[0m op \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_jit_get_operation(qualified_op_name)\n\u001b[0;32m     64\u001b[0m \u001b[39m# let the script frontend know that op is identical to the builtin op\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39m# with qualified_op_name\u001b[39;00m\n\u001b[0;32m     66\u001b[0m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_builtins\u001b[39m.\u001b[39m_register_builtin(op, qualified_op_name)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No such operator image::read_file"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_iter, _ = d2l.load_data_bananas(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6330671cf013f9362c2cd1e55198b197db19b836250c5c20ff0742b9c9511c0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
