{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['banana-detection'] = (d2l.DATA_URL + 'banana-detection.zip', '5de26c8fce5ccdea9f91267273464dc968d20d72')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def read_data_bananas(is_train=True):\n",
    "    \"\"\"读取香蕉检测数据集中的图像和标签\"\"\"\n",
    "    data_dir = d2l.download_extract('banana-detection')\n",
    "    csv_fname = os.path.join(data_dir, 'bananas_train' if is_train else 'bananas_val', 'label.csv')\n",
    "    csv_data = pd.read_csv(csv_fname)\n",
    "    csv_data = csv_data.set_index('img_name')\n",
    "    images, targets = [], []\n",
    "    for img_name, target in csv_data.iterrows():\n",
    "        images.append(torchvision.io.read_image(\n",
    "            os.path.join(data_dir, 'bananas_train' if is_train else 'bananas_val', 'images', str(img_name))))\n",
    "        # 这里的target包含（类别，左上角x，左上角y，右下角x，右下角y），\n",
    "        # 其中所有图像都具有相同的香蕉类（索引为0）\n",
    "        targets.append(list(target))\n",
    "    return images, torch.tensor(targets).unsqueeze(1) / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class BananasDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"一个用于加载香蕉检测数据集的自定义数据集\"\"\"\n",
    "    def __init__(self, is_train):\n",
    "        self.features, self.labels = read_data_bananas(is_train)\n",
    "        print('read ' + str(len(self.features)) + (f' training examples' if\n",
    "              is_train else f' validation examples'))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx].float(), self.labels[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_bananas(batch_size):\n",
    "    \"\"\"加载香蕉检测数据集\"\"\"\n",
    "    train_iter = torch.utils.data.DataLoader(BananasDataset(is_train=True),\n",
    "                                             batch_size, shuffle=True)\n",
    "    val_iter = torch.utils.data.DataLoader(BananasDataset(is_train=False),\n",
    "                                           batch_size)\n",
    "    return train_iter, val_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No such operator image::read_file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\D2L\\第13章\\13.6目标检测数据集.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m batch_size, edge_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m, \u001b[39m256\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_iter, _ \u001b[39m=\u001b[39m load_data_bananas(batch_size)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_iter))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape, batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;32md:\\Projects\\D2L\\第13章\\13.6目标检测数据集.ipynb Cell 5\u001b[0m in \u001b[0;36mload_data_bananas\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data_bananas\u001b[39m(batch_size):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\"\"加载香蕉检测数据集\"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_iter \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(BananasDataset(is_train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                              batch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     val_iter \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(BananasDataset(is_train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                            batch_size)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m train_iter, val_iter\n",
      "\u001b[1;32md:\\Projects\\D2L\\第13章\\13.6目标检测数据集.ipynb Cell 5\u001b[0m in \u001b[0;36mBananasDataset.__init__\u001b[1;34m(self, is_train)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, is_train):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m read_data_bananas(is_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mread \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)) \u001b[39m+\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m training examples\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m           is_train \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m validation examples\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32md:\\Projects\\D2L\\第13章\\13.6目标检测数据集.ipynb Cell 5\u001b[0m in \u001b[0;36mread_data_bananas\u001b[1;34m(is_train)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m images, targets \u001b[39m=\u001b[39m [], []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m img_name, target \u001b[39min\u001b[39;00m csv_data\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     images\u001b[39m.\u001b[39mappend(torchvision\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mread_image(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(data_dir, \u001b[39m'\u001b[39;49m\u001b[39mbananas_train\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mif\u001b[39;49;00m is_train \u001b[39melse\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mbananas_val\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mimages\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mstr\u001b[39;49m(img_name))))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# 这里的target包含（类别，左上角x，左上角y，右下角x，右下角y），\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# 其中所有图像都具有相同的香蕉类（索引为0）\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     targets\u001b[39m.\u001b[39mappend(\u001b[39mlist\u001b[39m(target))\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torchvision\\io\\image.py:222\u001b[0m, in \u001b[0;36mread_image\u001b[1;34m(path, mode)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_image\u001b[39m(path: \u001b[39mstr\u001b[39m, mode: ImageReadMode \u001b[39m=\u001b[39m ImageReadMode\u001b[39m.\u001b[39mUNCHANGED) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    Reads a JPEG or PNG image into a 3 dimensional RGB Tensor.\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39m    Optionally converts the image to the desired format.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39m        output (Tensor[image_channels, image_height, image_width])\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     data \u001b[39m=\u001b[39m read_file(path)\n\u001b[0;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m decode_image(data, mode)\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torchvision\\io\\image.py:42\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_file\u001b[39m(path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m     32\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m    Reads and outputs the bytes contents of a file as a uint8 Tensor\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m    with one dimension.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39m        data (Tensor)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mread_file(path)\n\u001b[0;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\d2l\\lib\\site-packages\\torch\\_ops.py:63\u001b[0m, in \u001b[0;36m_OpNamespace.__getattr__\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m# Get the op `my_namespace::my_op` if available. This will also check\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39m# for overloads and raise an exception if there are more than one.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m qualified_op_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m::\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, op_name)\n\u001b[1;32m---> 63\u001b[0m op \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_jit_get_operation(qualified_op_name)\n\u001b[0;32m     64\u001b[0m \u001b[39m# let the script frontend know that op is identical to the builtin op\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39m# with qualified_op_name\u001b[39;00m\n\u001b[0;32m     66\u001b[0m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_builtins\u001b[39m.\u001b[39m_register_builtin(op, qualified_op_name)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No such operator image::read_file"
     ]
    }
   ],
   "source": [
    "batch_size, edge_size = 32, 256\n",
    "train_iter, _ = load_data_bananas(batch_size)\n",
    "batch = next(iter(train_iter))\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\D2L\\第13章\\13.6目标检测数据集.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/D2L/%E7%AC%AC13%E7%AB%A0/13.6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%95%B0%E6%8D%AE%E9%9B%86.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m imgs \u001b[39m=\u001b[39m [batch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m:\u001b[39m10\u001b[39m]\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)] \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "imgs = [batch[0][0:10].permute(0, 2, 3, 1)] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6330671cf013f9362c2cd1e55198b197db19b836250c5c20ff0742b9c9511c0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
