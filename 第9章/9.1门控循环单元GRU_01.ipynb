{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)   # 这块自己写真复杂呀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3,  9,  2,  ...,  2,  1,  3],\n",
      "        [15,  4, 14,  ...,  4,  6, 11],\n",
      "        [17,  5,  3,  ...,  1,  4,  6],\n",
      "        ...,\n",
      "        [ 3,  1,  4,  ..., 12,  2, 13],\n",
      "        [ 6,  3, 15,  ...,  5,  1, 13],\n",
      "        [ 9,  2,  1,  ...,  4,  5, 10]]) tensor([[ 9,  2,  1,  ...,  1,  3,  5],\n",
      "        [ 4, 14, 18,  ...,  6, 11, 20],\n",
      "        [ 5,  3,  9,  ...,  4,  6, 11],\n",
      "        ...,\n",
      "        [ 1,  4,  1,  ...,  2, 13,  1],\n",
      "        [ 3, 15, 10,  ...,  1, 13, 14],\n",
      "        [ 2,  1, 13,  ...,  5, 10,  1]])\n",
      "tensor([[ 5, 13,  2,  ..., 15,  7,  6],\n",
      "        [20,  4,  8,  ...,  1, 21,  2],\n",
      "        [11,  1, 12,  ...,  7, 22,  2],\n",
      "        ...,\n",
      "        [ 1, 21, 14,  ..., 10,  2, 16],\n",
      "        [14,  8,  3,  ..., 12,  7, 17],\n",
      "        [ 1,  4,  6,  ...,  2, 15,  3]]) tensor([[13,  2,  1,  ...,  7,  6, 22],\n",
      "        [ 4,  8,  8,  ..., 21,  2,  5],\n",
      "        [ 1, 12,  4,  ..., 22,  2, 10],\n",
      "        ...,\n",
      "        [21, 14,  3,  ...,  2, 16,  4],\n",
      "        [ 8,  3,  1,  ...,  7, 17,  8],\n",
      "        [ 4,  6, 11,  ..., 15,  3,  1]])\n",
      "tensor([[22,  2,  6,  ...,  6, 11,  5],\n",
      "        [ 5,  6, 18,  ...,  8,  8,  2],\n",
      "        [10,  1,  3,  ...,  1,  5,  3],\n",
      "        ...,\n",
      "        [ 4, 15,  2,  ...,  1,  4,  6],\n",
      "        [ 8,  1, 14,  ...,  2,  1,  4],\n",
      "        [ 1,  7,  6,  ..., 12,  4, 13]]) tensor([[ 2,  6,  5,  ..., 11,  5,  6],\n",
      "        [ 6, 18,  1,  ...,  8,  2, 11],\n",
      "        [ 1,  3,  9,  ...,  5,  3,  4],\n",
      "        ...,\n",
      "        [15,  2,  1,  ...,  4,  6, 11],\n",
      "        [ 1, 14,  6,  ...,  1,  4, 15],\n",
      "        [ 7,  6,  1,  ...,  4, 13, 20]])\n",
      "tensor([[ 6, 18,  1,  ..., 18, 10,  2],\n",
      "        [11,  1, 14,  ...,  1,  8,  4],\n",
      "        [ 4,  6, 11,  ...,  1, 13,  2],\n",
      "        ...,\n",
      "        [11, 16,  5,  ...,  9,  5,  6],\n",
      "        [15, 15,  2,  ...,  3,  4, 21],\n",
      "        [20,  1,  3,  ...,  1, 14, 20]]) tensor([[18,  1,  4,  ..., 10,  2, 19],\n",
      "        [ 1, 14,  8,  ...,  8,  4,  3],\n",
      "        [ 6, 11,  1,  ..., 13,  2,  1],\n",
      "        ...,\n",
      "        [16,  5, 12,  ...,  5,  6, 18],\n",
      "        [15,  2, 20,  ...,  4, 21, 12],\n",
      "        [ 1,  3,  9,  ..., 14, 20,  7]])\n",
      "tensor([[19,  1,  2,  ...,  1, 14,  8],\n",
      "        [ 3,  1, 14,  ..., 14,  8,  1],\n",
      "        [ 1, 15,  4,  ...,  7, 22,  2],\n",
      "        ...,\n",
      "        [18,  1,  3,  ...,  1,  9,  4],\n",
      "        [12,  2,  1,  ..., 12,  1,  7],\n",
      "        [ 7,  6,  3,  ...,  4, 20,  8]]) tensor([[ 1,  2, 19,  ..., 14,  8, 14],\n",
      "        [ 1, 14, 20,  ...,  8,  1,  4],\n",
      "        [15,  4, 10,  ..., 22,  2, 10],\n",
      "        ...,\n",
      "        [ 1,  3,  9,  ...,  9,  4,  6],\n",
      "        [ 2,  1,  3,  ...,  1,  7, 15],\n",
      "        [ 6,  3,  9,  ..., 20,  8,  1]])\n",
      "tensor([[14,  4, 12,  ...,  4,  6,  5],\n",
      "        [ 4, 16,  3,  ..., 14, 18,  9],\n",
      "        [10,  3,  1,  ...,  8,  3,  1],\n",
      "        ...,\n",
      "        [ 6, 11,  1,  ...,  2, 17,  7],\n",
      "        [15,  3,  4,  ...,  2, 11,  1],\n",
      "        [ 1,  4,  1,  ...,  8,  8,  1]]) tensor([[ 4, 12, 12,  ...,  6,  5, 13],\n",
      "        [16,  3,  2,  ..., 18,  9,  3],\n",
      "        [ 3,  1,  7,  ...,  3,  1, 14],\n",
      "        ...,\n",
      "        [11,  1, 17,  ..., 17,  7, 10],\n",
      "        [ 3,  4, 18,  ..., 11,  1,  4],\n",
      "        [ 4,  1, 11,  ...,  8,  1, 15]])\n",
      "tensor([[13,  4,  3,  ..., 11,  1,  3],\n",
      "        [ 3,  1, 10,  ...,  4, 13, 13],\n",
      "        [14,  6,  5,  ..., 19,  1, 16],\n",
      "        ...,\n",
      "        [10, 23,  1,  ..., 15, 12,  7],\n",
      "        [ 4, 21,  7,  ...,  6,  3,  1],\n",
      "        [15,  4,  6,  ...,  1,  8,  2]]) tensor([[ 4,  3,  2,  ...,  1,  3,  9],\n",
      "        [ 1, 10,  7,  ..., 13, 13,  2],\n",
      "        [ 6,  5, 22,  ...,  1, 16,  7],\n",
      "        ...,\n",
      "        [23,  1,  8,  ..., 12,  7, 15],\n",
      "        [21,  7, 14,  ...,  3,  1,  7],\n",
      "        [ 4,  6, 11,  ...,  8,  2, 22]])\n",
      "tensor([[ 9,  2,  1,  ..., 15,  2,  6],\n",
      "        [ 2, 12,  8,  ...,  7,  1, 14],\n",
      "        [ 7, 10,  5,  ...,  9,  7,  7],\n",
      "        ...,\n",
      "        [15, 23,  1,  ...,  1, 17,  4],\n",
      "        [ 7, 16,  1,  ...,  9,  2,  4],\n",
      "        [22,  2, 10,  ...,  1, 17,  4]]) tensor([[ 2,  1,  8,  ...,  2,  6,  3],\n",
      "        [12,  8,  1,  ...,  1, 14,  8],\n",
      "        [10,  5,  6,  ...,  7,  7, 12],\n",
      "        ...,\n",
      "        [23,  1,  4,  ..., 17,  4,  8],\n",
      "        [16,  1,  3,  ...,  2,  4, 10],\n",
      "        [ 2, 10,  4,  ..., 17,  4,  8]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_iter:\n",
    "    print(x, y)\n",
    "    exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "    \n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * .01     # 均值0、方差.01\n",
    "\n",
    "    def three():\n",
    "        return (normal((num_inputs, num_hiddens)),\n",
    "                normal((num_hiddens, num_hiddens)),\n",
    "                torch.zeros(num_hiddens, device=device))\n",
    "    \n",
    "    W_xz, W_hz, b_z = three()   # 更新门参数\n",
    "    W_xr, W_hr, b_r = three()   # 重置门参数\n",
    "    W_xh, W_hh, b_h = three()   # 候选隐状态参数\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "\n",
    "    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gru_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros(size=(batch_size, num_hiddens), device=device), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(inputs, state, params):\n",
    "    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z)\n",
    "        R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r)\n",
    "        H_tilda = torch.tanh((X @ W_xh) + ((R * H) @ W_hh) + b_h)\n",
    "        H = Z * H + (1 - Z) * H_tilda\n",
    "        Y = H @ W_hq + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu()\n",
    "num_epochs, lr = 500, 1\n",
    "model = d2l.RNNModelScratch(vocab_size, num_hiddens, device, get_params, init_gru_state, gru)\n",
    "# d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6330671cf013f9362c2cd1e55198b197db19b836250c5c20ff0742b9c9511c0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
